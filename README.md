# Capstone Project

This project addresses a classification problem using both Hyperparameters HyperDrive and Automated Machine Learning (AutoML) to optimize and deploy the best model. The objective is to utilize both the HyperDrive and AutoML APIs provided by Azure to develop and refine this project.
The dataset for this project pertains to the survival probability of Titanic passengers, which has been sourced from Kaggle. The comprehensive steps involved in this project are as follows:

1. Dataset Selection:
- Select the Titanic passenger survival probability dataset as the primary dataset for this project.
2. Data Importation:
- Import the chosen dataset into the Azure workspace for further analysis and model training.
3. Model Training:
- Automated Machine Learning (AutoML): Leverage Azure's AutoML to automate the process of model selection and hyperparameter tuning.
- HyperDrive: Employ HyperDrive to further fine-tune hyperparameters and optimize model performance.
4. Model Comparison:
- Evaluate and compare the performance of the models generated by AutoML and HyperDrive to determine the most effective model.
5. Model Deployment:
- Deploy the best-performing model to a production environment for real-world application.
6. Endpoint Testing:
- Test the deployed model's endpoint to ensure it operates correctly and delivers accurate predictions.

## Project Set Up and Installation
*OPTIONAL:* If your project has any special installation steps, this is where you should put it. To turn this project into a professional portfolio project, you are encouraged to explain how to set up this project in AzureML.

## Dataset
This is the Titanic dataset taken from Kaggle with link: https://www.kaggle.com/c/titanic/data 
Below is description of data:
- Survived: if the passenger survived or not (True/False)
- Pclass: the	Ticket class	(1 = 1st, 2 = 2nd, 3 = 3rd)
- Sex:	Gender	(Male, Female)
- Age: the passenger's age (20, 30, 45, ...)
- SibSp: the	number of siblings / spouses	(0, 2, 3, ...)
- Parch: the	number of parents / children (0, 1, 2, ...)
- Ticket:	the ticket id (A/5 21171, ...)
- Fare: the	Passenger fare (10.34, 8.50, ...)
- Cabin: the	cabin id	(A12, B34, ...)
- Embarked: the	Port of Embarkation	(C = Cherbourg, Q = Queenstown, S = Southampton)
### Project steps:
1. Dataset description
- The Titanic survival dataset consists of 12 features and a total of 891 records. The dataset is sourced from Kaggle and provides historical data on Titanic passengers, including their demographic details, ticket information, and survival status.
- Survival Status: 342 passengers survived. 549 passengers did not survive.
- Survival Rate: The survival rate is approximately 38% across the dataset.
- The goal of this project is to build a classification model that can predict the survival probability of passengers based on the provided features. 
- To get the dataset, we can download from Kaggle. Import Dataset: Upload the dataset to the Azure workspace for further processing and analysis.

2. Hyperparameter Tuning
- Select Hyperparameters: hyperparameters such as C (regularization parameter) and max_iters (maximum iterations) for tuning.
- Submit Run: Execute the model training run with the selected hyperparameters and record the run with the highest accuracy.
- Register Best Model: Save and register the model that achieved the best performance during hyperparameter tuning.

3. Auto ML
- Dataset Preparation: Use the same Titanic survival dataset.
- Configure AutoML Settings: Set up AutoML with primary metrics, maximum iterations, and timeout settings to automate the process of model selection and tuning.
- Register Best Model: Save and register the best-performing model.

4. Model Comparison
- Evaluate Models: Compare the accuracy and performance of the models trained using hyperparameter tuning and AutoML.
- Select Best Model: Identify the model with the superior accuracy for deployment.

5. Model Deployment
- Deploy Model: Deploy the best model.
- Prepare for Inference: Download the environment and the score.py script from the best run to configure the inference pipeline.
- Check Endpoint Status: Verify that the endpoint deployment is healthy and ready for use.

6. Endpoint Testing
- Send Post Request: Send a post request to the deployed model's endpoint to obtain predictions.
- Compare Predictions: Evaluate the predictions against the ground truth values to assess the model's performance.

### Task
*TODO*: Explain the task you are going to be solving with this dataset and the features you will be using for it.

### Access
*TODO*: Explain how you are accessing the data in your workspace.

## Automated ML
*TODO*: Give an overview of the `automl` settings and configuration you used for this experiment

### Results
*TODO*: What are the results you got with your automated ML model? What were the parameters of the model? How could you have improved it?

*TODO* Remeber to provide screenshots of the `RunDetails` widget as well as a screenshot of the best model trained with it's parameters.

## Hyperparameter Tuning
*TODO*: What kind of model did you choose for this experiment and why? Give an overview of the types of parameters and their ranges used for the hyperparameter search


### Results
*TODO*: What are the results you got with your model? What were the parameters of the model? How could you have improved it?

*TODO* Remeber to provide screenshots of the `RunDetails` widget as well as a screenshot of the best model trained with it's parameters.

## Model Deployment
*TODO*: Give an overview of the deployed model and instructions on how to query the endpoint with a sample input.

## Screen Recording
*TODO* Provide a link to a screen recording of the project in action. Remember that the screencast should demonstrate:
- A working model
- Demo of the deployed  model
- Demo of a sample request sent to the endpoint and its response

## Standout Suggestions
*TODO (Optional):* This is where you can provide information about any standout suggestions that you have attempted.
